{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DATA_ROOT = \"./ml100marathon-02-01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667753, 22)\n",
      "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
      "0  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
      "1  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
      "2  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
      "3  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
      "4    73611         2099    12034.0        100:10      99.0     20160207.0   \n",
      "\n",
      "   Date  label  weekday  weekday_type  ...  weekday_3  weekday_4  weekday_5  \\\n",
      "0   NaN      0      3.0             0  ...          1          0          0   \n",
      "1   NaN      0      6.0             0  ...          0          0          0   \n",
      "2   NaN      0      5.0             0  ...          0          0          1   \n",
      "3   NaN      0      5.0             0  ...          0          0          1   \n",
      "4   NaN      0      7.0             0  ...          0          0          0   \n",
      "\n",
      "   weekday_6  weekday_7  discount_rate  discount_man  discount_jian  \\\n",
      "0          0          0           0.95            20              1   \n",
      "1          1          0           0.95            20              1   \n",
      "2          0          0           0.90           200             20   \n",
      "3          0          0           0.50            10              5   \n",
      "4          0          1           0.90           100             10   \n",
      "\n",
      "   discount_type  is_train  \n",
      "0              1      True  \n",
      "1              1      True  \n",
      "2              1      True  \n",
      "3              1      True  \n",
      "4              1      True  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "(79216, 22)\n",
      "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
      "0  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
      "1   163606         1569     5054.0        200:30      10.0     20160421.0   \n",
      "2  4061024         3381     7610.0        200:20      10.0     20160426.0   \n",
      "3   106443          450     3732.0          30:5      99.0     20160429.0   \n",
      "4   114747         1569     5054.0        200:30       9.0     20160426.0   \n",
      "\n",
      "   Date  label  weekday  weekday_type  ...  weekday_3  weekday_4  weekday_5  \\\n",
      "0   NaN      0      5.0             0  ...          0          0          1   \n",
      "1   NaN      0      4.0             0  ...          0          1          0   \n",
      "2   NaN      0      2.0             0  ...          0          0          0   \n",
      "3   NaN      0      5.0             0  ...          0          0          1   \n",
      "4   NaN      0      2.0             0  ...          0          0          0   \n",
      "\n",
      "   weekday_6  weekday_7  discount_rate  discount_man  discount_jian  \\\n",
      "0          0          0       0.900000           200             20   \n",
      "1          0          0       0.850000           200             30   \n",
      "2          0          0       0.900000           200             20   \n",
      "3          0          0       0.833333            30              5   \n",
      "4          0          0       0.850000           200             30   \n",
      "\n",
      "   discount_type  is_train  \n",
      "0              1     False  \n",
      "1              1     False  \n",
      "2              1     False  \n",
      "3              1     False  \n",
      "4              1     False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_ROOT,'train.csv'))\n",
    "valid = pd.read_csv(os.path.join(DATA_ROOT,'valid.csv'))\n",
    "print(train.shape)\n",
    "print(train.head())\n",
    "print(valid.shape)\n",
    "print(valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "original_feature = [ 'discount_rate',\n",
    "                            'discount_type',\n",
    "                            'discount_man', \n",
    "                            'discount_jian',\n",
    "                            'Distance', \n",
    "                            'weekday', \n",
    "                            'weekday_type'] + weekdaycols\n",
    "print(len(original_feature),original_feature)\n",
    "predictors = original_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(train[predictors].astype(float))\n",
    "X_test = sc_X.transform(valid[predictors].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "0   1.720632e-01\n",
      "1   1.507219e-01\n",
      "2   9.997941e-02\n",
      "3   9.361897e-02\n",
      "4   8.910377e-02\n",
      "5   8.684127e-02\n",
      "6   8.536624e-02\n",
      "7   8.524878e-02\n",
      "8   7.542036e-02\n",
      "9   5.508153e-02\n",
      "10  6.554548e-03\n",
      "11  3.451848e-29\n",
      "12  7.429750e-30\n",
      "13  5.180427e-35\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = None)\n",
    "#pca = PCA(n_components = 7)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(pd.DataFrame(explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=4, max_iter=1000)\n",
    "classifier.fit(X_train, train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest to the Training set\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#classifier = RandomForestClassifier(\n",
    "        #n_estimators = 100, \n",
    "        #max_depth = 10,\n",
    "        #min_samples_split = 75,\n",
    "        #min_samples_leaf =10,\n",
    "        #max_features = 10,\n",
    "        #criterion = 'entropy',\n",
    "        #oob_score = True,\n",
    "        #n_jobs = 4,\n",
    "        #verbose = 1\n",
    "    #)\n",
    "#classifier.fit(X_train, train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75356    28]\n",
      " [ 3830     2]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "valid_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(valid['label'], valid_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 19)\n",
      "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
      "0  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
      "1  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
      "2  1439408         2632     8591.0          20:1       0.0     20160516.0   \n",
      "3  2029232          450     1532.0          30:5       0.0     20160530.0   \n",
      "4  2029232         6459    12737.0          20:1       0.0     20160519.0   \n",
      "\n",
      "   weekday  weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
      "0        6             0          0          0          0          0   \n",
      "1        1             0          1          0          0          0   \n",
      "2        1             0          1          0          0          0   \n",
      "3        1             0          1          0          0          0   \n",
      "4        4             0          0          0          0          1   \n",
      "\n",
      "   weekday_5  weekday_6  weekday_7  discount_rate  discount_man  \\\n",
      "0          0          1          0       0.866667           150   \n",
      "1          0          0          0       0.950000            20   \n",
      "2          0          0          0       0.950000            20   \n",
      "3          0          0          0       0.833333            30   \n",
      "4          0          0          0       0.950000            20   \n",
      "\n",
      "   discount_jian  discount_type  \n",
      "0             20              1  \n",
      "1              1              1  \n",
      "2              1              1  \n",
      "3              5              1  \n",
      "4              1              1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 15)\n",
      "   discount_rate  discount_type  discount_man  discount_jian  Distance  \\\n",
      "0       0.866667              1           150             20       1.0   \n",
      "1       0.950000              1            20              1       0.0   \n",
      "2       0.950000              1            20              1       0.0   \n",
      "3       0.833333              1            30              5       0.0   \n",
      "4       0.950000              1            20              1       0.0   \n",
      "\n",
      "   weekday  weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
      "0        6             0          0          0          0          0   \n",
      "1        1             0          1          0          0          0   \n",
      "2        1             0          1          0          0          0   \n",
      "3        1             0          1          0          0          0   \n",
      "4        4             0          0          0          0          1   \n",
      "\n",
      "   weekday_5  weekday_6  weekday_7  pred_prob  \n",
      "0          0          1          0   0.086022  \n",
      "1          0          0          0   0.013800  \n",
      "2          0          0          0   0.013800  \n",
      "3          0          0          0   0.054679  \n",
      "4          0          0          0   0.136206  \n"
     ]
    }
   ],
   "source": [
    "dftest = pd.read_csv(os.path.join(DATA_ROOT,'test.csv'))\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "\n",
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "print(targetset.head())\n",
    "\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "y_test = pca.transform(testset[predictors])\n",
    "\n",
    "y_test_pred = classifier.predict_proba(y_test)\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "print(test1.shape)\n",
    "print(test1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n",
      "   User_id Coupon_id Date_received  pred_prob                     uid\n",
      "0  1439408     11002      20160528   0.086022  1439408_11002_20160528\n",
      "1  1439408      8591      20160613   0.013800   1439408_8591_20160613\n",
      "2  1439408      8591      20160516   0.013800   1439408_8591_20160516\n",
      "3  2029232      1532      20160530   0.054679   2029232_1532_20160530\n",
      "4  2029232     12737      20160519   0.136206  2029232_12737_20160519\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "print(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.063223\n",
      "1  1000020_8192_20160513  0.065458\n",
      "2  1000065_1455_20160527  0.054612\n",
      "3  1000085_8067_20160513  0.023103\n",
      "4  1000086_2418_20160613  0.054679\n"
     ]
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(os.path.join(DATA_ROOT,\"results.csv\"), header=[\"uid\", \"label\"], index=False) # submission format\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
